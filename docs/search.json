[
  {
    "objectID": "mp01.html",
    "href": "mp01.html",
    "title": "Mini Project 1: Exploring the Most Popular Programming on Netflix",
    "section": "",
    "text": "This analysis looks at Netflix viewing trends around the world, covering 94 countries with a date range from 2021-07-04 to 2025-08-24. This report examines what people are watching, which shows and movies are the most popular, and how preferences can vary by region. The data set includes 2791 unique titles."
  },
  {
    "objectID": "mp01.html#executive-summary",
    "href": "mp01.html#executive-summary",
    "title": "Mini Project 1: Exploring the Most Popular Programming on Netflix",
    "section": "",
    "text": "This analysis looks at Netflix viewing trends around the world, covering 94 countries with a date range from 2021-07-04 to 2025-08-24. This report examines what people are watching, which shows and movies are the most popular, and how preferences can vary by region. The data set includes 2791 unique titles."
  },
  {
    "objectID": "mp01.html#exploratory-questions",
    "href": "mp01.html#exploratory-questions",
    "title": "Mini Project 1: Exploring the Most Popular Programming on Netflix",
    "section": "Exploratory Questions",
    "text": "Exploratory Questions\n1. How many different countries does Netflix operate in?\n\n\nShow code\ncountry_count &lt;- COUNTRY_TOP_10 |&gt; \n  distinct(country_iso2) |&gt; \n  nrow()\n\n\nNetflix operates in [94] countries.\n2. Which non-English-language film has spent the most cumulative weeks in the global top 10? How many weeks did it spend?\n\n\nShow code\nnon_english_film &lt;- GLOBAL_TOP_10 |&gt;\n  filter(category == \"Films (Non-English)\") |&gt;\n  group_by(show_title) |&gt;\n  summarise(total_weeks = max(cumulative_weeks_in_top_10, na.rm = TRUE)) |&gt;\n  arrange(desc(total_weeks)) |&gt;\n  slice(1)\n\nnon_english_film_title &lt;- non_english_film$show_title[1]\nnon_english_film_weeks &lt;- non_english_film$total_weeks[1]\n\n\nThe non-English film with the most weeks in the global Top 10 is [All Quiet on the Western Front], with [23] weeks.\n3. What is the longest film (English or non-English) to have ever appeared in the Netflix global Top 10? How long is it in minutes?\n\n\nShow code\nlongest_film &lt;- GLOBAL_TOP_10 |&gt;\n  filter(str_detect(category, \"Films\")) |&gt;\n  filter(!is.na(runtime)) |&gt;\n  mutate(runtime_minutes = round(60 * runtime)) |&gt;\n  arrange(desc(runtime_minutes)) |&gt;\n  slice(1)\n\nlongest_film_title &lt;- longest_film$show_title[1]\nlongest_film_minutes &lt;- longest_film$runtime_minutes[1]\n\n\nThe longest film to appear in the Netflix global Top 10 is [Pushpa 2: The Rule (Reloaded Version)], with a runtime of [224] minutes.\n4. For each of the four categories, what program has the most total hours of global viewership?\n\n\nShow code\ntop_programs_by_category &lt;- GLOBAL_TOP_10 |&gt;\n  group_by(category, show_title) |&gt;\n  summarise(total_hours = sum(weekly_hours_viewed, na.rm = TRUE), .groups = \"drop\") |&gt;\n  group_by(category) |&gt;\n  slice_max(total_hours, n = 1) |&gt;\n  arrange(desc(total_hours))\ntop_programs_by_category |&gt;\n  mutate(total_hours = scales::comma(total_hours)) |&gt;\n  select(category, show_title, total_hours) |&gt;\n  format_titles() |&gt;\n  datatable(\n    options = list(searching = FALSE, info = FALSE),\n    caption = \"Top Programs by Category\"\n  )\n\n\n\n\n\n\n5. Which TV show had the longest run in a country’s Top 10? How long was this run and in what country did it occur?\n\n\nShow code\nlongest_country_run &lt;- COUNTRY_TOP_10 |&gt;\n  filter(str_detect(category, \"TV\")) |&gt;\n  group_by(country_name, show_title) |&gt;\n  summarise(max_weeks = max(cumulative_weeks_in_top_10, na.rm = TRUE), .groups = \"drop\") |&gt;\n  arrange(desc(max_weeks)) |&gt;\n  slice(1)\n\nlongest_country_run_title &lt;- longest_country_run$show_title[1]\nlongest_country_run_country &lt;- longest_country_run$country_name[1]\nlongest_country_run_weeks &lt;- longest_country_run$max_weeks[1]\n\n\nThe TV show with the longest run in a country’s Top 10 is [Money Heist], lasting [127] weeks in [Pakistan].\n6. Netflix provides over 200 weeks of service history for all but one country in our data set. Which country is this and when did Netflix cease operations in that country?\n\n\nShow code\nlibrary(lubridate)\ncountry_weeks &lt;- COUNTRY_TOP_10 |&gt;\n  group_by(country_name) |&gt;\n  summarise(\n    weeks_count = n_distinct(week),\n    last_week = max(week, na.rm = TRUE),\n    .groups = \"drop\"\n  ) |&gt;\n  filter(weeks_count &lt; 200) |&gt;\n  arrange(weeks_count)\n\nshort_country_name &lt;- country_weeks$country_name[1]\nshort_country_weeks &lt;- country_weeks$weeks_count[1]\nshort_country_last_week &lt;- country_weeks$last_week[1]\n\n\nThe country with fewer than 200 weeks of service history is [Russia], with [35] weeks of data. Netflix ceased operations there in [2022-02-27].\n7. What is the total viewership of the TV show Squid Game? Note that there are three seasons total and we are looking for the total number of hours watched across all seasons.\n\n\nShow code\nsquid_game_total &lt;- GLOBAL_TOP_10 |&gt;\n  filter(str_detect(show_title, \"Squid Game\")) |&gt;\n  summarise(total_hours = sum(weekly_hours_viewed, na.rm = TRUE)) |&gt;\n  pull(total_hours)\nsquid_game_total_fmt &lt;- scales::comma(squid_game_total)\n\n\nThe total viewership of Squid Game across all seasons is [5,310,000,000] hours.\n8. The movie Red Notice has a runtime of 1 hour and 58 minutes. Approximately how many views did it receive in 2021?\n\n\nShow code\nlibrary(lubridate)\n\nred_notice_2021 &lt;- GLOBAL_TOP_10 |&gt;\n  filter(show_title == \"Red Notice\", year(week) == 2021) |&gt;\n  summarise(total_views = sum(weekly_views, na.rm = TRUE)) |&gt;\n  pull(total_views)\n\n\nThe movie Red Notice received approximately [0] views in 2021.\n9. How many Films reached Number 1 in the US but did not originally debut there? That is, find films that first appeared on the Top 10 chart at, e.g., Number 4 but then became more popular and eventually hit Number 1? What is the most recent film to pull this off?\n\n\nShow code\n# Filter US films and calculate debut and whether they ever hit #1\nus_films &lt;- COUNTRY_TOP_10 |&gt;\n  filter(country_name == \"United States\", str_detect(category, \"Films\")) |&gt;\n  group_by(show_title) |&gt;\n  arrange(week) |&gt;\n  mutate(\n    ever_hit_1 = any(weekly_rank == 1),\n    debut_rank = first(weekly_rank),\n    latest_week = max(week)\n  ) |&gt;\n  filter(ever_hit_1 == TRUE, debut_rank &gt; 1) |&gt;\n  ungroup()\n\n# Total number of films\nus_films_count &lt;- nrow(distinct(us_films, show_title))\n\n# Most recent film to achieve this\nmost_recent_us_film &lt;- us_films |&gt;\n  arrange(desc(latest_week)) |&gt;\n  slice(1) |&gt;\n  pull(show_title)\n\n\n[45] films are eventually reached Number 1 in the US despite not debuting there. The most recent film to achieve this feat is [KPop Demon Hunters].\n10. Which TV show/season hit the top 10 in the most countries in its debut week? In how many countries did it chart?\n\n\nShow code\ntv_debut_countries &lt;- COUNTRY_TOP_10 |&gt;\n  filter(str_detect(category, \"TV\")) |&gt;\n  group_by(show_title) |&gt;\n  filter(week == min(week)) |&gt;\n  summarise(countries_count = n_distinct(country_name), .groups = \"drop\") |&gt;\n  arrange(desc(countries_count)) |&gt;\n  slice(1)\n\ntop_tv_debut_title &lt;- tv_debut_countries$show_title[1]\ntop_tv_debut_countries &lt;- tv_debut_countries$countries_count[1]\n\n\nThe TV show/season that hit the Top 10 in the most countries during its debut week is [Emily in Paris], charting in [94] countries."
  },
  {
    "objectID": "mp01.html#press-releases",
    "href": "mp01.html#press-releases",
    "title": "Mini Project 1: Exploring the Most Popular Programming on Netflix",
    "section": "Press Releases",
    "text": "Press Releases\nONE - Upcoming Season of Stranger Things\n\n\nShow code\n# Analyze Stranger Things most recent season data\nstranger_things_data &lt;- GLOBAL_TOP_10 |&gt;\n  filter(str_detect(show_title, \"Stranger\")) |&gt;\n  arrange(desc(week)) |&gt;\n  slice_head(n = 50) |&gt;\n  summarise(\n    total_viewing_hours = sum(weekly_hours_viewed, na.rm = TRUE),\n    max_weeks = max(cumulative_weeks_in_top_10, na.rm = TRUE)\n  )\n\n# Extract values for inline use\nstranger_total_hours &lt;- stranger_things_data$total_viewing_hours\nstranger_max_weeks   &lt;- stranger_things_data$max_weeks\n\n# Find comparable English TV shows\ncomparable_shows &lt;- GLOBAL_TOP_10 |&gt;\n  filter(category == \"TV (English)\", !str_detect(show_title, \"Stranger\")) |&gt;\n  group_by(show_title) |&gt;\n  summarise(total_hours = sum(weekly_hours_viewed, na.rm = TRUE), .groups = \"drop\") |&gt;\n  arrange(desc(total_hours)) |&gt;\n  slice(1:2)\n\ncomparable_show_1 &lt;- comparable_shows$show_title[1]\ncomparable_show_2 &lt;- comparable_shows$show_title[2]\n\n\nThe Stranger Things franchise has dominated Netflix, with over [2,950,400,000] hours viewed and a presence in the Top 10 for [19] weeks. Its cultural impact rivals other English-language juggernauts such as [Wednesday] and [Bridgerton], underscoring the show’s massive international appeal.\nTWO - Commercial Success in India\n\n\nShow code\n# Analysis focusing on India's overall Netflix market\n\n# Count total unique shows that appeared in India's Top 10\nindia_total_shows &lt;- COUNTRY_TOP_10 |&gt;\n  filter(country_name == \"India\") |&gt;\n  distinct(show_title) |&gt;\n  nrow()\n\n# Count total weeks of content in India's Top 10 (all rows = weeks tracked)\nindia_total_weeks &lt;- COUNTRY_TOP_10 |&gt;\n  filter(country_name == \"India\") |&gt;\n  nrow()\n\n# Shows in India\nindia_shows &lt;- COUNTRY_TOP_10 |&gt;\n  filter(country_name == \"India\") |&gt;\n  group_by(show_title) |&gt;\n  summarise(weeks = n(), .groups = \"drop\") |&gt;\n  arrange(desc(weeks))\n\n# Shows in US\nus_shows &lt;- COUNTRY_TOP_10 |&gt;\n  filter(country_name == \"United States\") |&gt;\n  distinct(show_title)\n\n# Popular in India but not in US\nindia_only &lt;- anti_join(india_shows, us_shows, by = \"show_title\")\n\npopular_show_not_in_US &lt;- if (nrow(india_only) &gt; 0) {\n  india_only$show_title[1]\n} else {\n  \"regional content\"\n}\n\n# Most popular show in India (longest weeks)\nmost_popular_india &lt;- india_shows |&gt;\n  slice_max(order_by = weeks, n = 1)\n\ntop_show_india &lt;- if (nrow(most_popular_india) &gt; 0) {\n  most_popular_india$show_title\n} else {\n  \"top shows\"\n}\n\n# Count shows with 10+ weeks\nlong_running_shows &lt;- india_shows |&gt;\n  filter(weeks &gt;= 10) |&gt;\n  nrow()\n\n# Growth trend by month\nindia_monthly &lt;- COUNTRY_TOP_10 |&gt;\n  filter(country_name == \"India\") |&gt;\n  mutate(month = format(week, \"%Y-%m\")) |&gt;\n  group_by(month) |&gt;\n  summarise(shows = n_distinct(show_title), .groups = \"drop\") |&gt;\n  arrange(month)\n\ngrowth_trend &lt;- if (nrow(india_monthly) &gt; 1) {\n  if (tail(india_monthly$shows, 1) &gt; head(india_monthly$shows, 1)) {\n    \"increased\"\n  } else if (tail(india_monthly$shows, 1) &lt; head(india_monthly$shows, 1)) {\n    \"decreased\"\n  } else {\n    \"remained stable\"\n  }\n} else {\n  \"grown\"\n}\n\n# Average number of shows per month (not per week, since aggregation is monthly)\navg_shows_per_week &lt;- round(mean(india_monthly$shows, na.rm = TRUE))\n\n# Subscriber estimate (external data, static input)\nsubscriber_estimate &lt;- \"30–40 million\"\n\n\nNetflix continues to grow in India, with a total of [1164] unique shows entering the country’s Top 10 list, spanning [4400] total weeks of appearances.One standout title was [Money Heist], which spent the most weeks on the chart. Interestingly, shows like [The Great Indian Kapil Show] found success in India but not in the U.S., highlighting the strength of regional content.Currently, [81] shows have managed to stay in India’s Top 10 for more than 10 weeks, a strong indicator of lasting popularity.The overall number of unique shows featured in India’s Top 10 has [decreased] over time, with an average of about [39] new shows per month.With an estimated [30–40 million] subscribers in India, Netflix’s presence in the country continues to expand, making it one of the platform’s most dynamic markets.\nTHREE - Non-English Films Take the World by Storm on Netflix!\n\n\nShow code\n# Non-English film with most cumulative weeks in global Top 10\nnon_english_film &lt;- GLOBAL_TOP_10 |&gt;\n  filter(category == \"Films (Non-English)\") |&gt;\n  group_by(show_title) |&gt;\n  summarise(\n    total_weeks = max(cumulative_weeks_in_top_10, na.rm = TRUE),\n    total_hours = sum(weekly_hours_viewed, na.rm = TRUE),\n    .groups = \"drop\"\n  ) |&gt;\n  arrange(desc(total_weeks)) |&gt;\n  slice(1)\n\nnon_english_film_title &lt;- non_english_film$show_title[1]\nnon_english_film_weeks &lt;- non_english_film$total_weeks[1]\nnon_english_film_hours &lt;- non_english_film$total_hours[1]\n\n# Count total countries the film appeared in using COUNTRY_TOP_10\ntotal_countries_non_english &lt;- COUNTRY_TOP_10 |&gt;\n  filter(show_title == non_english_film_title) |&gt;\n  distinct(country_name) |&gt;\n  nrow()\n\n\nNetflix’s top non-English film captivated global audiences, spending [23] weeks in the global Top 10, reaching viewers in [91] countries, amassing [176,490,000] total hours of global viewership, and outpacing many popular English-language films in audience engagement, proving that international stories are now dominating screens worldwide."
  },
  {
    "objectID": "mp01.html#initial-data-exploration",
    "href": "mp01.html#initial-data-exploration",
    "title": "Mini Project 1: Exploring the Most Popular Programming on Netflix",
    "section": "Initial Data Exploration",
    "text": "Initial Data Exploration\n\n\nShow code\n# Acquire Data\nif(!dir.exists(file.path(\"data\", \"mp01\"))){\n  dir.create(file.path(\"data\", \"mp01\"), showWarnings=FALSE, recursive=TRUE)\n}\n\nGLOBAL_TOP_10_FILENAME &lt;- file.path(\"data\", \"mp01\", \"global_top10_alltime.csv\")\nif(!file.exists(GLOBAL_TOP_10_FILENAME)){\n  download.file(\"https://www.netflix.com/tudum/top10/data/all-weeks-global.tsv\", \n                destfile=GLOBAL_TOP_10_FILENAME)\n}\n\nCOUNTRY_TOP_10_FILENAME &lt;- file.path(\"data\", \"mp01\", \"country_top10_alltime.csv\")\nif(!file.exists(COUNTRY_TOP_10_FILENAME)){\n  download.file(\"https://www.netflix.com/tudum/top10/data/all-weeks-countries.tsv\", \n                destfile=COUNTRY_TOP_10_FILENAME)\n}\n\n# Load Libraries\nif(!require(\"tidyverse\")) install.packages(\"tidyverse\")\nlibrary(readr)\nlibrary(dplyr)\nlibrary(stringr)\nlibrary(DT)\n\n# Import Data\nGLOBAL_TOP_10 &lt;- read_tsv(GLOBAL_TOP_10_FILENAME, show_col_types = FALSE) |&gt;\n  mutate(season_title = if_else(season_title %in% c(\"N/A\", \"\"), NA_character_, season_title))\n\nCOUNTRY_TOP_10 &lt;- read_tsv(COUNTRY_TOP_10_FILENAME, na = \"N/A\", show_col_types = FALSE) |&gt;\n  mutate(season_title = if_else(season_title == \"\", NA_character_, season_title))\n\n# Helper Function\nformat_titles &lt;- function(df){\n  colnames(df) &lt;- str_replace_all(colnames(df), \"_\", \" \") |&gt; str_to_title()\n  df\n}\n\n# Summary Stats (no dataset printed)\ntotal_countries &lt;- COUNTRY_TOP_10 |&gt; distinct(country_iso2) |&gt; nrow()\ndate_range &lt;- paste(min(GLOBAL_TOP_10$week), \"to\", max(GLOBAL_TOP_10$week))\ntotal_shows &lt;- GLOBAL_TOP_10 |&gt; distinct(show_title) |&gt; nrow()\n\n\n\n\nShow code\n# Top 10 Table\nGLOBAL_TOP_10 |&gt; \n  mutate(`Runtime_(Minutes)` = round(60 * runtime)) |&gt;\n  select(-season_title, -runtime) |&gt;\n  format_titles() |&gt;\n  head(20) |&gt;\n  datatable(\n    options = list(searching = FALSE, info = FALSE)\n  ) |&gt;\n  formatRound(c(\"Weekly Hours Viewed\", \"Weekly Views\"))"
  },
  {
    "objectID": "mp02.html",
    "href": "mp02.html",
    "title": "Mini Project 2: Making Backyards Affordable for All",
    "section": "",
    "text": "Housing affordability is under pressure across many U.S. metro areas. YIMBY (“Yes In My Back Yard”) argues that building more homes—via permissive zoning, faster approvals, and denser infill—can ease rent growth and keep cities open to newcomers. In contrast, NIMBY restrictions limit supply and push prices up. Useful signals come from metro-level trends in median rent and income, population and households, and the pace of new housing permits. Metros that add homes faster than population grows tend to experience lower rent pressure and more inclusive economic growth."
  },
  {
    "objectID": "mp02.html#executive-summary",
    "href": "mp02.html#executive-summary",
    "title": "Mini Project 2: Making Backyards Affordable for All",
    "section": "",
    "text": "xxx90"
  },
  {
    "objectID": "mp02.html#initial-data-exploration",
    "href": "mp02.html#initial-data-exploration",
    "title": "Mini Project 2: Making Backyards Affordable for All",
    "section": "Initial Data Exploration",
    "text": "Initial Data Exploration\n\n\nShow code\n# Census Data\nif(!dir.exists(file.path(\"data\", \"mp02\"))){\n    dir.create(file.path(\"data\", \"mp02\"), showWarnings=FALSE, recursive=TRUE)\n}\n\nensure_package &lt;- function(pkg){\n    pkg &lt;- as.character(substitute(pkg))\n    options(repos = c(CRAN = \"https://cloud.r-project.org\"))\n    if(!require(pkg, character.only=TRUE, quietly=TRUE)) install.packages(pkg)\n    stopifnot(require(pkg, character.only=TRUE, quietly=TRUE))\n}\n\nensure_package(tidyverse)\nensure_package(glue)\nensure_package(readxl)\nensure_package(tidycensus)\n\nget_acs_all_years &lt;- function(variable, geography=\"cbsa\",\n                              start_year=2009, end_year=2023){\n    fname &lt;- glue(\"{variable}_{geography}_{start_year}_{end_year}.csv\")\n    fname &lt;- file.path(\"data\", \"mp02\", fname)\n    \n    if(!file.exists(fname)){\n        YEARS &lt;- seq(start_year, end_year)\n        YEARS &lt;- YEARS[YEARS != 2020] # Drop 2020 - No survey (covid)\n        \n        ALL_DATA &lt;- map(YEARS, function(yy){\n            tidycensus::get_acs(geography, variable, year=yy, survey=\"acs1\") |&gt;\n                mutate(year=yy) |&gt;\n                select(-moe, -variable) |&gt;\n                rename(!!variable := estimate)\n        }) |&gt; bind_rows()\n        \n        write_csv(ALL_DATA, fname)\n    }\n    \n    read_csv(fname, show_col_types=FALSE)\n}\n\n# Household income (12 month)\nINCOME &lt;- get_acs_all_years(\"B19013_001\") |&gt;\n    rename(household_income = B19013_001)\n\n# Monthly rent\nRENT &lt;- get_acs_all_years(\"B25064_001\") |&gt;\n    rename(monthly_rent = B25064_001)\n\n# Total population\nPOPULATION &lt;- get_acs_all_years(\"B01003_001\") |&gt;\n    rename(population = B01003_001)\n\n# Total number of households\nHOUSEHOLDS &lt;- get_acs_all_years(\"B11001_001\") |&gt;\n    rename(households = B11001_001)\n\n#the number of new housing units built each year\nget_building_permits &lt;- function(start_year = 2009, end_year = 2023){\n    fname &lt;- glue(\"housing_units_{start_year}_{end_year}.csv\")\n    fname &lt;- file.path(\"data\", \"mp02\", fname)\n    \n    if(!file.exists(fname)){\n        HISTORICAL_YEARS &lt;- seq(start_year, 2018)\n        \n        HISTORICAL_DATA &lt;- map(HISTORICAL_YEARS, function(yy){\n            historical_url &lt;- glue(\"https://www.census.gov/construction/bps/txt/tb3u{yy}.txt\")\n                \n            LINES &lt;- readLines(historical_url)[-c(1:11)]\n\n            CBSA_LINES &lt;- str_detect(LINES, \"^[[:digit:]]\")\n            CBSA &lt;- as.integer(str_sub(LINES[CBSA_LINES], 5, 10))\n\n            PERMIT_LINES &lt;- str_detect(str_sub(LINES, 48, 53), \"[[:digit:]]\")\n            PERMITS &lt;- as.integer(str_sub(LINES[PERMIT_LINES], 48, 53))\n            \n            data_frame(CBSA = CBSA,\n                       new_housing_units_permitted = PERMITS, \n                       year = yy)\n        }) |&gt; bind_rows()\n        \n        CURRENT_YEARS &lt;- seq(2019, end_year)\n        \n        CURRENT_DATA &lt;- map(CURRENT_YEARS, function(yy){\n            current_url &lt;- glue(\"https://www.census.gov/construction/bps/xls/msaannual_{yy}99.xls\")\n            \n            temp &lt;- tempfile()\n            \n            download.file(current_url, destfile = temp, mode=\"wb\")\n            \n            fallback &lt;- function(.f1, .f2){\n                function(...){\n                    tryCatch(.f1(...), \n                             error=function(e) .f2(...))\n                }\n            }\n            \n            reader &lt;- fallback(read_xlsx, read_xls)\n            \n            reader(temp, skip=5) |&gt;\n                na.omit() |&gt;\n                select(CBSA, Total) |&gt;\n                mutate(year = yy) |&gt;\n                rename(new_housing_units_permitted = Total)\n        }) |&gt; bind_rows()\n        \n        ALL_DATA &lt;- rbind(HISTORICAL_DATA, CURRENT_DATA)\n        \n        write_csv(ALL_DATA, fname)\n        \n    }\n    \n    read_csv(fname, show_col_types=FALSE)\n}\n\nPERMITS &lt;- get_building_permits()\n\n# Latest NAICS data schema\nensure_package(httr2)\nensure_package(rvest)\nget_bls_industry_codes &lt;- function(){\n    fname &lt;- fname &lt;- file.path(\"data\", \"mp02\", \"bls_industry_codes.csv\")\n    \n    if(!file.exists(fname)){\n    \n        resp &lt;- request(\"https://www.bls.gov\") |&gt; \n            req_url_path(\"cew\", \"classifications\", \"industry\", \"industry-titles.htm\") |&gt;\n            req_headers(`User-Agent` = \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:143.0) Gecko/20100101 Firefox/143.0\") |&gt; \n            req_error(is_error = \\(resp) FALSE) |&gt;\n            req_perform()\n        \n        resp_check_status(resp)\n        \n        naics_table &lt;- resp_body_html(resp) |&gt;\n            html_element(\"#naics_titles\") |&gt; \n            html_table() |&gt;\n            mutate(title = str_trim(str_remove(str_remove(`Industry Title`, Code), \"NAICS\"))) |&gt;\n            select(-`Industry Title`) |&gt;\n            mutate(depth = if_else(nchar(Code) &lt;= 5, nchar(Code) - 1, NA)) |&gt;\n            filter(!is.na(depth))\n        \n        naics_table &lt;- naics_table |&gt; \n            filter(depth == 4) |&gt; \n            rename(level4_title=title) |&gt; \n            mutate(level1_code = str_sub(Code, end=2), \n                   level2_code = str_sub(Code, end=3), \n                   level3_code = str_sub(Code, end=4)) |&gt;\n            left_join(naics_table, join_by(level1_code == Code)) |&gt;\n            rename(level1_title=title) |&gt;\n            left_join(naics_table, join_by(level2_code == Code)) |&gt;\n            rename(level2_title=title) |&gt;\n            left_join(naics_table, join_by(level3_code == Code)) |&gt;\n            rename(level3_title=title) |&gt;\n            select(-starts_with(\"depth\")) |&gt;\n            rename(level4_code = Code) |&gt;\n            select(level1_title, level2_title, level3_title, level4_title, \n                   level1_code,  level2_code,  level3_code,  level4_code)\n    \n        write_csv(naics_table, fname)\n    }\n    \n    read_csv(fname, show_col_types=FALSE)\n    \n}\n\nINDUSTRY_CODES &lt;- get_bls_industry_codes()\n\n# BLS Quarterly Census of Employment and Wages\nensure_package(httr2)\nensure_package(rvest)\nget_bls_qcew_annual_averages &lt;- function(start_year=2009, end_year=2023){\n    fname &lt;- glue(\"bls_qcew_{start_year}_{end_year}.csv.gz\")\n    fname &lt;- file.path(\"data\", \"mp02\", fname)\n    \n    YEARS &lt;- seq(start_year, end_year)\n    YEARS &lt;- YEARS[YEARS != 2020] # Drop Covid year to match ACS\n    \n    if(!file.exists(fname)){\n        ALL_DATA &lt;- map(YEARS, .progress=TRUE, possibly(function(yy){\n            fname_inner &lt;- file.path(\"data\", \"mp02\", glue(\"{yy}_qcew_annual_singlefile.zip\"))\n            \n            if(!file.exists(fname_inner)){\n                request(\"https://www.bls.gov\") |&gt; \n                    req_url_path(\"cew\", \"data\", \"files\", yy, \"csv\",\n                                 glue(\"{yy}_annual_singlefile.zip\")) |&gt;\n                    req_headers(`User-Agent` = \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:143.0) Gecko/20100101 Firefox/143.0\") |&gt; \n                    req_retry(max_tries=5) |&gt;\n                    req_perform(fname_inner)\n            }\n            \n            if(file.info(fname_inner)$size &lt; 755e5){\n                warning(sQuote(fname_inner), \"appears corrupted. Please delete and retry this step.\")\n            }\n            \n            read_csv(fname_inner, \n                     show_col_types=FALSE) |&gt; \n                mutate(YEAR = yy) |&gt;\n                select(area_fips, \n                       industry_code, \n                       annual_avg_emplvl, \n                       total_annual_wages, \n                       YEAR) |&gt;\n                filter(nchar(industry_code) &lt;= 5, \n                       str_starts(area_fips, \"C\")) |&gt;\n                filter(str_detect(industry_code, \"-\", negate=TRUE)) |&gt;\n                mutate(FIPS = area_fips, \n                       INDUSTRY = as.integer(industry_code), \n                       EMPLOYMENT = as.integer(annual_avg_emplvl), \n                       TOTAL_WAGES = total_annual_wages) |&gt;\n                select(-area_fips, \n                       -industry_code, \n                       -annual_avg_emplvl, \n                       -total_annual_wages) |&gt;\n                # 10 is a special value: \"all industries\" , so omit\n                filter(INDUSTRY != 10) |&gt; \n                mutate(AVG_WAGE = TOTAL_WAGES / EMPLOYMENT)\n        })) |&gt; bind_rows()\n        \n        write_csv(ALL_DATA, fname)\n    }\n    \n    ALL_DATA &lt;- read_csv(fname, show_col_types=FALSE)\n    \n    ALL_DATA_YEARS &lt;- unique(ALL_DATA$YEAR)\n    \n    YEARS_DIFF &lt;- setdiff(YEARS, ALL_DATA_YEARS)\n    \n    if(length(YEARS_DIFF) &gt; 0){\n        stop(\"Download failed for the following years: \", YEARS_DIFF, \n             \". Please delete intermediate files and try again.\")\n    }\n    \n    ALL_DATA\n}\n\nWAGES &lt;- get_bls_qcew_annual_averages()\n\nCBSA_LOOKUP &lt;- INCOME |&gt;\n  dplyr::select(GEOID, NAME) |&gt;\n  dplyr::distinct() |&gt;\n  dplyr::mutate(CBSA = as.integer(GEOID))\n\nstate_df &lt;- tibble::tibble(\n  abb  = c(state.abb, \"DC\", \"PR\"),\n  name = c(state.name, \"District of Columbia\", \"Puerto Rico\")\n)"
  },
  {
    "objectID": "mp02.html#q1-which-cbsa-permitted-the-largest-number-of-new-housing-units-20102019-inclusive",
    "href": "mp02.html#q1-which-cbsa-permitted-the-largest-number-of-new-housing-units-20102019-inclusive",
    "title": "Mini Project 2: Making Backyards Affordable for All",
    "section": "Q1: Which CBSA permitted the largest number of new housing units (2010–2019 inclusive)?",
    "text": "Q1: Which CBSA permitted the largest number of new housing units (2010–2019 inclusive)?\n\n\nShow code\ntop_permits_2010_2019 &lt;- PERMITS |&gt;\nfilter(year &gt;= 2010, year &lt;= 2019) |&gt;\ngroup_by(CBSA) |&gt;\nsummarise(total_permits = sum(new_housing_units_permitted, na.rm = TRUE), .groups = \"drop\") |&gt;\nleft_join(CBSA_LOOKUP, by = \"CBSA\") |&gt;\narrange(desc(total_permits))\n\nDT::datatable(top_permits_2010_2019 |&gt; slice_head(n = 15),\ncaption = \"Top CBSAs by total new housing units permitted (2010–2019)\",\noptions = list(pageLength = 15)) |&gt;\nDT::formatCurrency(\"total_permits\", currency = \"\", digits = 0)"
  },
  {
    "objectID": "mp02.html#q2-in-what-year-did-albuquerque-nm-cbsa-10740-permit-the-most-new-housing-units",
    "href": "mp02.html#q2-in-what-year-did-albuquerque-nm-cbsa-10740-permit-the-most-new-housing-units",
    "title": "Mini Project 2: Making Backyards Affordable for All",
    "section": "Q2: In what year did Albuquerque, NM (CBSA 10740) permit the most new housing units?",
    "text": "Q2: In what year did Albuquerque, NM (CBSA 10740) permit the most new housing units?\n\n\nShow code\n# In what year did Albuquerque, NM (CBSA 10740) permit the most new housing units?\nabq_permits &lt;- PERMITS |&gt;\nfilter(CBSA == 10740) |&gt;\narrange(desc(new_housing_units_permitted))\n\n# Interactive table\nDT::datatable(abq_permits,\ncaption = \"Albuquerque (CBSA 10740) — new housing units by year\",\noptions = list(pageLength = 15))\n\n\n\n\n\n\nShow code\nabq_top &lt;- abq_permits |&gt;\ndplyr::slice_max(new_housing_units_permitted, n = 1, with_ties = TRUE)\n\nq2_years &lt;- paste0(abq_top$year, collapse = \", \")\nq2_units &lt;- abq_top$new_housing_units_permitted[1]\nq2_tie &lt;- nrow(abq_top) &gt; 1\n\n\n\n\n\n\n\n\nAnswer\n\n\n\nThe year 2021 had the most new housing units permitted in Albuquerque (CBSA 10740) which is 4,021 units.\n\n\n\nQ3: Which state had the highest average individual income in 2015?\n\n\nShow code\n# Which state had the highest average individual income in 2015?\nstate_df &lt;- data.frame(\n  abb  = c(state.abb, \"DC\", \"PR\"),\n  name = c(state.name, \"District of Columbia\", \"Puerto Rico\")\n)\n\nq3_result &lt;- INCOME |&gt;\n  filter(year == 2015) |&gt;\n  left_join(HOUSEHOLDS |&gt; filter(year == 2015), \n            by = c(\"GEOID\", \"NAME\", \"year\")) |&gt;\n  left_join(POPULATION |&gt; filter(year == 2015), \n            by = c(\"GEOID\", \"NAME\", \"year\")) |&gt;\n  mutate(state = str_extract(NAME, \", (.{2})\", group = 1),\n         total_income = household_income * households) |&gt;\n  group_by(state) |&gt;\n  summarize(\n    total_income = sum(total_income, na.rm = TRUE),\n    total_population = sum(population, na.rm = TRUE),\n    avg_individual_income = total_income / total_population,\n    .groups = \"drop\"\n  ) |&gt;\n  arrange(desc(avg_individual_income)) |&gt;\n  left_join(state_df, by = c(\"state\" = \"abb\"))\n\n# Display top 10\nq3_result |&gt;\n  slice(1:10) |&gt;\n  select(State = name, \n         Abbr = state, \n         `Avg Income` = avg_individual_income, \n         Population = total_population) |&gt;\n  mutate(\n    `Avg Income` = scales::dollar(`Avg Income`, accuracy = 1),\n    Population = scales::comma(Population, accuracy = 1)\n  ) |&gt;\n  DT::datatable(\n    caption = \"States by Average Individual Income, 2015 (annual dollars)\",\n    options = list(\n      pageLength = 15,\n      columnDefs = list(list(className = 'dt-right', targets = 2:3))\n    ),\n    rownames = FALSE\n  )\n\n\n\n\n\n\nShow code\nq3_top &lt;- q3_result |&gt;\ndplyr::slice_max(avg_individual_income, n = 1, with_ties = TRUE)\n\nq3_states &lt;- q3_top |&gt;\ndplyr::mutate(lbl = dplyr::coalesce(name, state)) |&gt;\ndplyr::pull(lbl) |&gt;\npaste0(collapse = \"; \")\n\nq3_income &lt;- scales::dollar(q3_top$avg_individual_income[1], accuracy = 1)\n\n\n\n\n\n\n\n\nAnswer\n\n\n\nThe highest average individual income in 2015 is District of Columbia at $33,233.\n\n\n\n\nQ4: Data scientists and business analysts are recorded under NAICS code 5182. What is the last year in which the NYC CBSA had the most data scientists in the country?\n\n\nShow code\n# What is the last year in which the NYC CBSA had the most data scientists in the country? \n\ndata_scientists &lt;- WAGES |&gt;\n  filter(INDUSTRY == 5182) |&gt;\n  mutate(std_cbsa = paste0(FIPS, \"0\")) |&gt;\n  select(std_cbsa, YEAR, EMPLOYMENT)\n\nq4_result &lt;- data_scientists |&gt;\n  group_by(YEAR) |&gt;\n  slice_max(EMPLOYMENT, n = 1, with_ties = FALSE) |&gt;\n  ungroup() |&gt;\n  left_join(\n    POPULATION |&gt; \n      mutate(std_cbsa = paste0(\"C\", GEOID)) |&gt;\n      select(std_cbsa, NAME) |&gt;\n      distinct(),\n    by = \"std_cbsa\"\n  )\n\n# Result\nq4_result |&gt;\n  select(Year = YEAR, \n         `Metro Area` = NAME, \n         Employment = EMPLOYMENT) |&gt;\n  mutate(Employment = scales::comma(Employment)) |&gt;\n  DT::datatable(\n    caption = \"CBSA with Most Data Scientists by Year (NAICS 5182)\",\n    options = list(\n      pageLength = 15,\n      columnDefs = list(list(className = 'dt-right', targets = 2))\n    ),\n    rownames = FALSE\n  )\n\n\n\n\n\n\nShow code\nnyc_lead_rows &lt;- q4_result |&gt;\ndplyr::filter(stringr::str_detect(NAME, stringr::regex(\"^New York\", ignore_case = TRUE)))\n\nif (nrow(nyc_lead_rows) &gt; 0) {\nq4_nyc_last &lt;- nyc_lead_rows |&gt;\ndplyr::slice_max(YEAR, n = 1, with_ties = FALSE)\nq4_last_year &lt;- q4_nyc_last$YEAR[1]\nq4_last_emp &lt;- q4_nyc_last$EMPLOYMENT[1]\n} else {\nq4_last_year &lt;- NA_integer_\nq4_last_emp &lt;- NA_real_\n}\n\n\n\n\n\n\n\n\nAnswer\n\n\n\nThe last year that NYC CBSA led NAICS 5182 employment is 2015 and the employment that year is 18,922.\n\n\n\n\nQ5: What fraction of total wages in NYC CBSA were earned in Finance & Insurance (NAICS 52)? When did it peak?\n\n\nShow code\n# Filter\nnyc_fin_share &lt;- WAGES |&gt;\n  filter(FIPS == \"C3562\") |&gt;\n  group_by(YEAR) |&gt;\n  summarise(\n    total_wages = sum(TOTAL_WAGES, na.rm = TRUE),\n    fin_wages   = sum(TOTAL_WAGES[INDUSTRY == 52], na.rm = TRUE),\n    .groups = \"drop\"\n  ) |&gt;\n  mutate(fin_share = fin_wages / total_wages) |&gt;\n  arrange(YEAR)\n\n# Format\nlibrary(scales)\nlibrary(DT)\n\nnyc_fin_share_pretty &lt;- nyc_fin_share |&gt;\n  mutate(\n    `Total Wages (Billions USD)` = total_wages / 1e9,\n    `Finance & Insurance Wages (Billions USD)` = fin_wages / 1e9,\n    `Finance Share (%)` = fin_share * 100\n  ) |&gt;\n  select(\n    Year = YEAR,\n    `Total Wages (Billions USD)`,\n    `Finance & Insurance Wages (Billions USD)`,\n    `Finance Share (%)`\n  )\n\n# Display\ndatatable(\n  nyc_fin_share_pretty,\n  options = list(pageLength = 10),\n  caption = \"Share of Total NYC Wages from Finance & Insurance (NAICS 52) by Year\",\n  rownames = FALSE\n) |&gt;\n  formatRound(columns = 2:4, digits = 2)\n\n\n\n\n\n\n\n\n\n\n\n\nAnswer\n\n\n\nThe peak Finance & Insurance wage share in the NYC CBSA is 4.60% in 2014\n($119,105,615,711 of $2,587,096,519,796)."
  },
  {
    "objectID": "mp02.html#q3-which-state-had-the-highest-average-individual-income-in-2015",
    "href": "mp02.html#q3-which-state-had-the-highest-average-individual-income-in-2015",
    "title": "Mini Project 2: Making Backyards Affordable for All",
    "section": "Q3: Which state had the highest average individual income in 2015?",
    "text": "Q3: Which state had the highest average individual income in 2015?\n\n\nShow code\nstate_income_2015 &lt;- INCOME |&gt;\n  dplyr::filter(year == 2015) |&gt;\n  dplyr::select(GEOID, NAME, year, household_income) |&gt;\n  dplyr::inner_join(HOUSEHOLDS |&gt; dplyr::filter(year == 2015) |&gt; dplyr::select(GEOID, households),\n                    by = \"GEOID\") |&gt;\n  dplyr::inner_join(POPULATION |&gt; dplyr::filter(year == 2015) |&gt; dplyr::select(GEOID, population),\n                    by = \"GEOID\") |&gt;\n  dplyr::mutate(state = stringr::str_extract(NAME, \"[A-Z]{2}$\"),\n                total_income_cbsa = household_income * households) |&gt;\n  dplyr::group_by(state) |&gt;\n  dplyr::summarise(total_income_state = sum(total_income_cbsa, na.rm = TRUE),\n                   total_population_state = sum(population, na.rm = TRUE),\n                   .groups = \"drop\") |&gt;\n  dplyr::mutate(avg_individual_income = total_income_state / pmax(total_population_state, 1)) |&gt;\n  dplyr::left_join(state_df, by = c(\"state\" = \"abb\")) |&gt;\n  dplyr::arrange(dplyr::desc(avg_individual_income))\n\nDT::datatable(\n  state_income_2015 |&gt;\n    dplyr::mutate(avg_individual_income = scales::dollar(avg_individual_income)),\n  caption = \"Average individual income by state (2015) — computed from CBSA totals\",\n  options = list(pageLength = 10)\n)"
  },
  {
    "objectID": "mp02.html#q4-last-year-nyc-cbsa-had-the-most-data-scientists-naics-5182",
    "href": "mp02.html#q4-last-year-nyc-cbsa-had-the-most-data-scientists-naics-5182",
    "title": "Mini Project 2: Making Backyards Affordable for All",
    "section": "Q4: Last year NYC CBSA had the most data scientists (NAICS 5182)?",
    "text": "Q4: Last year NYC CBSA had the most data scientists (NAICS 5182)?\n\n\nShow code\ncbsa_names &lt;- CBSA_LOOKUP |&gt;\n  dplyr::transmute(cbsa5 = sprintf(\"%05d\", CBSA), NAME)\n\nwages_with_cbsa5 &lt;- WAGES |&gt;\n  dplyr::mutate(\n    cbsa5_raw = stringr::str_extract(FIPS, \"\\\\d+\"),\n    cbsa5     = dplyr::if_else(nchar(cbsa5_raw) &gt;= 5,\n                               stringr::str_sub(cbsa5_raw, 1, 5),\n                               cbsa5_raw)\n  )\n\nds_annual_leaders &lt;- wages_with_cbsa5 |&gt;\n  dplyr::filter(INDUSTRY == 5182) |&gt;\n  dplyr::group_by(YEAR, cbsa5) |&gt;\n  dplyr::summarise(EMPLOYMENT = sum(EMPLOYMENT, na.rm = TRUE), .groups = \"drop_last\") |&gt;\n  dplyr::slice_max(order_by = EMPLOYMENT, n = 1, with_ties = FALSE) |&gt;\n  dplyr::ungroup() |&gt;\n  dplyr::left_join(cbsa_names, by = \"cbsa5\")\n\nnyc_last_leader_year &lt;- ds_annual_leaders |&gt;\n  dplyr::filter(stringr::str_detect(NAME, stringr::regex(\"^New York\", ignore_case = TRUE))) |&gt;\n  dplyr::summarise(last_year_NYC_led = max(YEAR, na.rm = TRUE))\n\nds_annual_leaders_table &lt;- ds_annual_leaders |&gt;\n  dplyr::arrange(YEAR) |&gt;\n  dplyr::mutate(EMPLOYMENT = scales::comma(EMPLOYMENT))\n\nDT::datatable(ds_annual_leaders_table,\n              caption = \"CBSA with most NAICS 5182 employment by year\",\n              options = list(pageLength = 15))\n\n\n\n\n\n\nShow code\nnyc_last_leader_year\n\n\n# A tibble: 1 × 1\n  last_year_NYC_led\n              &lt;dbl&gt;\n1              -Inf"
  },
  {
    "objectID": "mp02.html#q5-what-fraction-of-total-wages-in-nyc-cbsa-were-earned-in-finance-insurance-naics-52-when-did-it-peak",
    "href": "mp02.html#q5-what-fraction-of-total-wages-in-nyc-cbsa-were-earned-in-finance-insurance-naics-52-when-did-it-peak",
    "title": "Mini Project 2: Making Backyards Affordable for All",
    "section": "Q5: What fraction of total wages in NYC CBSA were earned in Finance & Insurance (NAICS 52)? When did it peak?",
    "text": "Q5: What fraction of total wages in NYC CBSA were earned in Finance & Insurance (NAICS 52)? When did it peak?\n\n\nShow code\nnyc_cbsa5 &lt;- CBSA_LOOKUP |&gt;\n  dplyr::filter(stringr::str_detect(NAME, stringr::regex(\"^New York\", ignore_case = TRUE))) |&gt;\n  dplyr::pull(CBSA) |&gt;\n  {\\(x) sprintf(\"%05d\", x[1])}()\n\nif(!exists(\"wages_with_cbsa5\")){\n  cbsa_names &lt;- CBSA_LOOKUP |&gt;\n    dplyr::transmute(cbsa5 = sprintf(\"%05d\", CBSA), NAME)\n\n  wages_with_cbsa5 &lt;- WAGES |&gt;\n    dplyr::mutate(\n      cbsa5_raw = stringr::str_extract(FIPS, \"\\\\d+\"),\n      cbsa5     = dplyr::if_else(nchar(cbsa5_raw) &gt;= 5,\n                                 stringr::str_sub(cbsa5_raw, 1, 5),\n                                 cbsa5_raw)\n    )\n}\n\nnyc_wage_shares &lt;- wages_with_cbsa5 |&gt;\n  dplyr::filter(cbsa5 == nyc_cbsa5) |&gt;\n  dplyr::group_by(YEAR) |&gt;\n  dplyr::summarise(\n    total_wages_all = sum(TOTAL_WAGES, na.rm = TRUE),\n    total_wages_fin = sum(TOTAL_WAGES[stringr::str_starts(as.character(INDUSTRY), \"52\")], na.rm = TRUE),\n    .groups = \"drop\"\n  ) |&gt;\n  dplyr::mutate(finance_share = total_wages_fin / pmax(total_wages_all, 1))\n\npeak_finance_share &lt;- nyc_wage_shares |&gt;\n  dplyr::slice_max(order_by = finance_share, n = 1)\n\nDT::datatable(\n  nyc_wage_shares |&gt;\n    dplyr::mutate(\n      total_wages_all = scales::dollar(total_wages_all),\n      total_wages_fin = scales::dollar(total_wages_fin)\n    ),\n  caption = \"NYC total wages & Finance/Insurance wages by year (BLS QCEW)\",\n  options = list(pageLength = 15)\n)\n\n\n\n\n\n\nShow code\npeak_finance_share\n\n\n# A tibble: 0 × 4\n# ℹ 4 variables: YEAR &lt;dbl&gt;, total_wages_all &lt;dbl&gt;, total_wages_fin &lt;dbl&gt;,\n#   finance_share &lt;dbl&gt;"
  },
  {
    "objectID": "mp02.html#introduction",
    "href": "mp02.html#introduction",
    "title": "Mini Project 2: Making Backyards Affordable for All",
    "section": "",
    "text": "Housing affordability is under pressure across many U.S. metro areas. YIMBY (“Yes In My Back Yard”) argues that building more homes—via permissive zoning, faster approvals, and denser infill—can ease rent growth and keep cities open to newcomers. In contrast, NIMBY restrictions limit supply and push prices up. Useful signals come from metro-level trends in median rent and income, population and households, and the pace of new housing permits. Metros that add homes faster than population grows tend to experience lower rent pressure and more inclusive economic growth."
  },
  {
    "objectID": "mp02.html#task-3-initial-visualization",
    "href": "mp02.html#task-3-initial-visualization",
    "title": "Mini Project 2: Making Backyards Affordable for All",
    "section": "Task 3: Initial Visualization",
    "text": "Task 3: Initial Visualization\n\nThe Relationship Between Monthly Rent and Average Household Income Per CBSA in 2009.\n\n\nShow code\n# Plot 1: Monthly Rent vs Household Income (CBSA, 2009)\nrent_income_2009 &lt;- RENT |&gt;\n  dplyr::filter(year == 2009) |&gt;\n  dplyr::select(GEOID, NAME, monthly_rent) |&gt;\n  dplyr::inner_join(\n    INCOME |&gt; dplyr::filter(year == 2009) |&gt; dplyr::select(GEOID, household_income),\n    by = \"GEOID\"\n  ) |&gt;\n  dplyr::filter(!is.na(monthly_rent), !is.na(household_income)) |&gt;\n  dplyr::mutate(rent_to_income = 12 * monthly_rent / household_income)\n\nggplot(rent_income_2009, aes(x = household_income, y = monthly_rent)) +\n  geom_point(alpha = 0.6, size = 2) +\n  geom_smooth(method = \"lm\", se = FALSE, linewidth = 0.9) +\n  scale_x_continuous(labels = scales::dollar_format()) +\n  scale_y_continuous(labels = scales::dollar_format()) +\n  labs(\n    title = \"Monthly Rent vs. Household Income (2009)\",\n    subtitle = \"Each point is a CBSA; line shows linear fit\",\n    x = \"Average household income (12-month, ACS 1-year)\",\n    y = \"Median gross rent (monthly, ACS 1-year)\",\n    caption = \"Source: ACS via tidycensus\"\n  ) +\n  theme_minimal(base_size = 13)\n\n\n\n\n\n\n\n\n\nThe scatter shows a clear positive association between household income and monthly rent across CBSAs: higher-income metros tend to have higher rents. The fitted line captures the overall trend, while the wider vertical spread at higher incomes suggests growing variation in rent among richer metros (possible heteroskedasticity). A few points sit above the trendline, indicating places where rents are high even after accounting for income—useful candidates when discussing rent burden later.\n\n\nThe Relationship Between Total Employment and Total Employment In The Health Care And Social Services Sector (NAICS 62) Across Different CBSAs.\n\n\nShow code\n# ---- Animated Plot 2: Health Care & Social Assistance vs Total Employment ----\n# (Drop this chunk in your Plot 2 section; it builds the needed data and fixes the errors.)\n\nif (!requireNamespace(\"gganimate\", quietly = TRUE)) install.packages(\"gganimate\")\nif (!requireNamespace(\"gifski\", quietly = TRUE))    install.packages(\"gifski\")\n\nlibrary(dplyr)\nlibrary(stringr)\nlibrary(tidyr)\nlibrary(ggplot2)\nlibrary(scales)\nlibrary(gganimate)\n\n# 0) Ensure we have CBSA ids for BLS table (if chunk order changes)\nif (!exists(\"wages_with_cbsa5\")) {\n  wages_with_cbsa5 &lt;- WAGES %&gt;%\n    mutate(\n      cbsa5_raw = str_extract(FIPS, \"\\\\d+\"),\n      cbsa5     = if_else(nchar(cbsa5_raw) &gt;= 5, str_sub(cbsa5_raw, 1, 5), cbsa5_raw)\n    )\n}\n\n# 1) Build total employment and NAICS 62 employment per CBSA-year\nemp_totals &lt;- wages_with_cbsa5 %&gt;%\n  group_by(YEAR, cbsa5) %&gt;%\n  summarise(total_emp = sum(EMPLOYMENT, na.rm = TRUE), .groups = \"drop\")\n\nemp_health &lt;- wages_with_cbsa5 %&gt;%\n  filter(str_starts(as.character(INDUSTRY), \"62\")) %&gt;%\n  group_by(YEAR, cbsa5) %&gt;%\n  summarise(health_emp = sum(EMPLOYMENT, na.rm = TRUE), .groups = \"drop\")\n\nemployment_health &lt;- emp_totals %&gt;%\n  left_join(emp_health, by = c(\"YEAR\", \"cbsa5\")) %&gt;%\n  mutate(health_emp = replace_na(health_emp, 0))\n\n# 2) Clean df for animation\neh &lt;- employment_health %&gt;%\n  transmute(\n    cbsa5,\n    year = as.integer(YEAR),\n    total_emp,\n    health_emp\n  ) %&gt;%\n  filter(is.finite(total_emp), is.finite(health_emp), is.finite(year))\n\nstopifnot(nrow(eh) &gt; 0)\n\n# 3) Animated scatter\np_anim &lt;- ggplot(eh, aes(x = total_emp, y = health_emp, group = cbsa5)) +\n  geom_point(aes(color = year), alpha = 0.7, size = 1.8) +\n  scale_color_viridis_c(option = \"plasma\") +\n  scale_x_continuous(labels = label_number(scale_cut = cut_short_scale())) +\n  scale_y_continuous(labels = label_number(scale_cut = cut_short_scale())) +\n  labs(\n    title = \"Health Care & Social Assistance vs. Total Employment\",\n    subtitle = \"Year: {frame_time}\",\n    x = \"Total Employment (All Industries)\",\n    y = \"Employment in NAICS 62\",\n    color = \"Year\",\n    caption = \"Source: BLS QCEW Annual Averages (2009–2023)\"\n  ) +\n  theme_minimal(base_size = 9) +\n  theme(\n    plot.title = element_text(face = \"bold\", hjust = 0.5, size = 10),\n    plot.subtitle = element_text(hjust = 0.5, size = 8),\n    axis.title = element_text(size = 8),\n    axis.text  = element_text(size = 7),\n    plot.caption = element_text(size = 9, hjust = 1),\n    panel.grid.minor = element_blank()\n  ) +\n  transition_time(year) +\n  shadow_mark(alpha = 0.15, size = 1) +\n  ease_aes(\"linear\")\n\n# 4) Render & save GIF\ndir.create(\"docs\", showWarnings = FALSE)\ngif_path &lt;- file.path(\"docs\", \"img_employment_health.gif\")\n\nanim &lt;- animate(\n  p_anim,\n  nframes = length(unique(eh$year)) * 6,\n  fps = 10,\n  width = 900, height = 600, units = \"px\",\n  renderer = gifski_renderer()\n)\nanim_save(gif_path, animation = anim)\n\n# 5) Show in the document\nknitr::include_graphics(gif_path)\n\n\n\n\n\n\n\n\n\nThe animation shows a strong, roughly proportional relationship between total employment and employment in NAICS 62 (Health Care & Social Assistance) across CBSAs. As the timeline advances from 2009 to 2023, the cloud of points shifts up and to the right, indicating broad-based labor market growth alongside a scaling health-care sector. CBSAs that sit above the main trend in a given year appear to be health-care-intensive (e.g., hospital/biomedical hubs), whereas those below the trend lean more toward other industries.\n\n\nThe Evolution of Average Household Size Over Time.\n\n\nShow code\n#Plot 3: Average Household Size Over Time (NYC & LA highlighted)\nif (!requireNamespace(\"gghighlight\", quietly = TRUE)) install.packages(\"gghighlight\")\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(gghighlight)\n\n# 1) Calculate household size (persons per household)\nhousehold_size &lt;- POPULATION %&gt;%\n  dplyr::inner_join(HOUSEHOLDS, by = c(\"GEOID\", \"NAME\", \"year\")) %&gt;%\n  dplyr::mutate(household_size = population / pmax(households, 1)) %&gt;%\n  dplyr::filter(is.finite(household_size), household_size &gt; 0)\n\n# 2) Select top 20 CBSAs by 2019 population for readability\ntop_cbsas &lt;- POPULATION %&gt;%\n  dplyr::filter(year == 2019) %&gt;%\n  dplyr::slice_max(population, n = 20) %&gt;%\n  dplyr::pull(GEOID)\n\nhousehold_size_subset &lt;- household_size %&gt;%\n  dplyr::filter(GEOID %in% top_cbsas) %&gt;%\n  dplyr::mutate(\n    highlight = NAME %in% c(\n      \"New York-Newark-Jersey City, NY-NJ-PA Metro Area\",\n      \"Los Angeles-Long Beach-Anaheim, CA Metro Area\"\n    )\n  )\n\n# 3) Plot with gghighlight\nggplot(household_size_subset, aes(x = year, y = household_size, group = NAME, color = NAME)) +\n  geom_line(linewidth = 0.8) +\n  gghighlight(\n    highlight,\n    use_direct_label = TRUE,\n    label_key = NAME,\n    label_params = list(size = 3.5, nudge_x = 0.5)\n  ) +\n  scale_y_continuous(limits = c(2, 3.5)) +\n  labs(\n    title = \"Evolution of Average Household Size Over Time\",\n    subtitle = \"Top 20 largest US metropolitan areas (2009–2023) — NYC and LA highlighted\",\n    x = \"Year\",\n    y = \"Average Household Size (persons per household)\",\n    caption = \"Source: US Census Bureau, ACS 1-year. Note: 2020 unavailable due to COVID-19.\"\n  ) +\n  theme_minimal(base_size = 12) +\n  theme(\n    plot.title = element_text(face = \"bold\", size = 14),\n    panel.grid.minor = element_blank(),\n    legend.position = \"none\"\n  )\n\n\n\n\n\n\n\n\n\nAcross the top 20 CBSAs, average household size is fairly stable from 2009 to 2023, with only modest drifts up or down. The highlighted lines show that NYC and Los Angeles track close to the pack, suggesting that changes in household composition are not dramatic at the metro scale. Small declines can reflect aging populations or more single-adult households, while slight increases may reflect multi-generational living or affordability pressures."
  },
  {
    "objectID": "mp02.html#the-evolution-of-average-household-size-over-time.",
    "href": "mp02.html#the-evolution-of-average-household-size-over-time.",
    "title": "Mini Project 2: Making Backyards Affordable for All",
    "section": "The Evolution of Average Household Size Over Time.",
    "text": "The Evolution of Average Household Size Over Time.\n\n\nShow code\n#Plot 3: Average Household Size Over Time (NYC & LA highlighted)\nif (!requireNamespace(\"gghighlight\", quietly = TRUE)) install.packages(\"gghighlight\")\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(gghighlight)\n\n# 1) Calculate household size (persons per household)\nhousehold_size &lt;- POPULATION %&gt;%\n  dplyr::inner_join(HOUSEHOLDS, by = c(\"GEOID\", \"NAME\", \"year\")) %&gt;%\n  dplyr::mutate(household_size = population / pmax(households, 1)) %&gt;%\n  dplyr::filter(is.finite(household_size), household_size &gt; 0)\n\n# 2) Select top 20 CBSAs by 2019 population for readability\ntop_cbsas &lt;- POPULATION %&gt;%\n  dplyr::filter(year == 2019) %&gt;%\n  dplyr::slice_max(population, n = 20) %&gt;%\n  dplyr::pull(GEOID)\n\nhousehold_size_subset &lt;- household_size %&gt;%\n  dplyr::filter(GEOID %in% top_cbsas) %&gt;%\n  dplyr::mutate(\n    highlight = NAME %in% c(\n      \"New York-Newark-Jersey City, NY-NJ-PA Metro Area\",\n      \"Los Angeles-Long Beach-Anaheim, CA Metro Area\"\n    )\n  )\n\n# 3) Plot with gghighlight\nggplot(household_size_subset, aes(x = year, y = household_size, group = NAME, color = NAME)) +\n  geom_line(linewidth = 0.8) +\n  gghighlight(\n    highlight,\n    use_direct_label = TRUE,\n    label_key = NAME,\n    label_params = list(size = 3.5, nudge_x = 0.5)\n  ) +\n  scale_y_continuous(limits = c(2, 3.5)) +\n  labs(\n    title = \"Evolution of Average Household Size Over Time\",\n    subtitle = \"Top 20 largest US metropolitan areas (2009–2023) — NYC and LA highlighted\",\n    x = \"Year\",\n    y = \"Average Household Size (persons per household)\",\n    caption = \"Source: US Census Bureau, ACS 1-year. Note: 2020 unavailable due to COVID-19.\"\n  ) +\n  theme_minimal(base_size = 12) +\n  theme(\n    plot.title = element_text(face = \"bold\", size = 14),\n    panel.grid.minor = element_blank(),\n    legend.position = \"none\"\n  )\n\n\n\n\n\n\n\n\n\nAcross the top 20 CBSAs, average household size is fairly stable from 2009 to 2023, with only modest drifts up or down. The highlighted lines show that NYC and Los Angeles track close to the pack, suggesting that changes in household composition are not dramatic at the metro scale. Small declines can reflect aging populations or more single-adult households, while slight increases may reflect multi-generational living or affordability pressures. This stability matters for interpretation later: large swings in rent burden are unlikely to be driven by shifts in household size alone, pointing instead to income, rents, and housing supply as primary levers."
  },
  {
    "objectID": "mp02.html#task-4-rent-burden",
    "href": "mp02.html#task-4-rent-burden",
    "title": "Mini Project 2: Making Backyards Affordable for All",
    "section": "Task 4: Rent Burden",
    "text": "Task 4: Rent Burden\nWe define rent burden as the share of a typical household’s income spent on rent: [ = ] For interpretability, we index this value so that 100 = the national, household-weighted average in the first study year.\n&gt; 100 ⇒ above-baseline (more burdened)\n&lt; 100 ⇒ below-baseline (less burdened)\n\n\nShow code\n# Uses: INCOME, RENT, HOUSEHOLDS, CBSA_LOOKUP (already created earlier)\n\nif (!requireNamespace(\"DT\", quietly = TRUE)) install.packages(\"DT\")\nlibrary(dplyr)\nlibrary(stringr)\nlibrary(scales)\n\n# 1) Join ACS tables and compute baseline rent-burden share\n#rb_share = annualized rent / household income\nRB_raw &lt;- INCOME %&gt;%\n  select(GEOID, NAME, year, household_income) %&gt;%\n  inner_join(RENT %&gt;% select(GEOID, year, monthly_rent),\n             by = c(\"GEOID\",\"year\")) %&gt;%\n  inner_join(HOUSEHOLDS %&gt;% select(GEOID, year, households),\n             by = c(\"GEOID\",\"year\")) %&gt;%\n  mutate(\n    rb_share = 12 * monthly_rent / pmax(household_income, 1)   # fraction of income spent on rent\n  ) %&gt;%\n  filter(is.finite(rb_share), rb_share &gt; 0)\n\n# First & last years present (2020 is already excluded in your imports)\nfirst_year &lt;- min(RB_raw$year, na.rm = TRUE)\nlast_year  &lt;- max(RB_raw$year, na.rm = TRUE)\n\n# Household-weighted NATIONAL average in the first year (baseline = 100)\nbaseline_val &lt;- RB_raw %&gt;%\n  filter(year == !!first_year) %&gt;%\n  summarise(baseline = weighted.mean(rb_share, w = households, na.rm = TRUE)) %&gt;%\n  pull(baseline)\n\n# 2) Build primary index + useful helper columns\nRB &lt;- RB_raw %&gt;%\n  mutate(\n    rb_index_100_first = 100 * rb_share / baseline_val,                    # main metric\n    rb_pct             = rb_share                                         # keep fraction for DT % formatting\n  )\n\n# 3) TABLE A: Time series for ONE metro (edit the name below as you wish)\ntarget_cbsa_name &lt;- \"New York-Newark-Jersey City, NY-NJ-PA Metro Area\"\n\nrb_timeseries &lt;- RB %&gt;%\n  filter(NAME == target_cbsa_name) %&gt;%\n  arrange(year) %&gt;%\n  transmute(\n    year,\n    `Monthly Rent`        = monthly_rent,\n    `Household Income`    = household_income,\n    `Rent Burden (share)` = rb_pct,\n    `Rent Burden Index`   = rb_index_100_first\n  )\n\nDT::datatable(\n  rb_timeseries,\n  caption = htmltools::tags$caption(\n    style = \"caption-side: top; text-align: left;\",\n    paste0(\"Rent burden over time — \", target_cbsa_name,\n           \" (Index: 100 = national household-weighted average in \", first_year, \")\")\n  ),\n  options = list(pageLength = 15)\n) |&gt;\n  DT::formatCurrency(c(\"Monthly Rent\",\"Household Income\"), currency = \"$\", digits = 0) |&gt;\n  DT::formatPercentage(\"Rent Burden (share)\", 1) |&gt;\n  DT::formatRound(\"Rent Burden Index\", digits = 1)\n\n\n\n\n\n\n\n\n\n\n\n\nThis table shows how rent burden changed over time for the metro you picked. The Rent Burden Index is set so that 100 equals the national household-weighted average in the first year. Values above 100 mean local households spend a bigger share of income on rent than that baseline; values below 100 mean they spend less. Read it left to right: if the index climbs, rent is rising faster than income (or income is falling); if it drops, income is catching up to rent. The “Monthly Rent” and “Household Income” columns help you see which side is moving most in each year.\n\n\n\n\n\nShow code\n# 4) TABLE B: Top/Bottom metros by rent burden in the latest year\nrb_latest &lt;- RB %&gt;%\n  filter(year == !!last_year) %&gt;%\n  arrange(desc(rb_index_100_first)) %&gt;%\n  transmute(\n    NAME,\n    `Monthly Rent`        = monthly_rent,\n    `Household Income`    = household_income,\n    `Rent Burden (share)` = rb_pct,\n    `Rent Burden Index`   = rb_index_100_first\n  )\n\n# Top 15 highest rent burden\nDT::datatable(\n  rb_latest %&gt;% slice_head(n = 15),\n  caption = htmltools::tags$caption(\n    style = \"caption-side: top; text-align: left;\",\n    paste0(\"Highest rent burden metros — \", last_year,\n           \" (Index: 100 = national household-weighted average in \", first_year, \")\")\n  ),\n  options = list(pageLength = 15)\n) |&gt;\n  DT::formatCurrency(c(\"Monthly Rent\",\"Household Income\"), currency = \"$\", digits = 0) |&gt;\n  DT::formatPercentage(\"Rent Burden (share)\", 1) |&gt;\n  DT::formatRound(\"Rent Burden Index\", digits = 1)\n\n\n\n\n\n\n\n\n\n\n\n\nThis table lists the metros where rent takes the largest share of income in the most recent year. A high index does not just mean “high rent”—it means rent is high relative to local incomes. These places face the most pressure on affordability right now. In many cases, that comes from rent growing faster than income, but sometimes it reflects slow income growth while rents stay elevated.\n\n\n\n\n\nShow code\n# Bottom 15 lowest rent burden\nDT::datatable(\n  rb_latest %&gt;% slice_tail(n = 15),\n  caption = htmltools::tags$caption(\n    style = \"caption-side: top; text-align: left;\",\n    paste0(\"Lowest rent burden metros — \", last_year,\n           \" (Index: 100 = national household-weighted average in \", first_year, \")\")\n  ),\n  options = list(pageLength = 15)\n) |&gt;\n  DT::formatCurrency(c(\"Monthly Rent\",\"Household Income\"), currency = \"$\", digits = 0) |&gt;\n  DT::formatPercentage(\"Rent Burden (share)\", 1) |&gt;\n  DT::formatRound(\"Rent Burden Index\", digits = 1)\n\n\n\n\n\n\nShow code\n# 5) One-line summary (optional)\nans_high &lt;- rb_latest %&gt;% slice_max(`Rent Burden Index`, n = 1)\nans_low  &lt;- rb_latest %&gt;% slice_min(`Rent Burden Index`, n = 1)\ncat(glue::glue(\n  \"In {last_year}, highest rent burden: {ans_high$NAME} (Index {round(ans_high$`Rent Burden Index`,1)}). \",\n  \"Lowest: {ans_low$NAME} (Index {round(ans_low$`Rent Burden Index`,1)}). \",\n  \"Index baseline = national household-weighted average in {first_year} (set to 100).\"\n))\n\n\nIn 2023, highest rent burden: Clearlake, CA Micro Area (Index 156.3). Lowest: Laconia, NH Micro Area (Index 63.9). Index baseline = national household-weighted average in 2009 (set to 100).\n\n\n\n\n\n\n\n\nHere you see metros where households spend a smaller share of income on rent than the baseline in the most recent year. A low index can come from lower rents, higher incomes, or both—so it doesn’t automatically mean rent is cheap in dollars. These metros are useful comparison points: they suggest conditions where incomes keep pace with housing costs or where supply keeps rents in check."
  },
  {
    "objectID": "mp02.html#task-5-housing-growth",
    "href": "mp02.html#task-5-housing-growth",
    "title": "Mini Project 2: Making Backyards Affordable for All",
    "section": "Task 5: Housing Growth",
    "text": "Task 5: Housing Growth\nWe combine POPULATION and PERMITS to see how much housing each CBSA is adding. We build two metrics: (1) an instantaneous rate—permits per 1,000 current residents (how much we’re building right now), and (2) a growth-adjusted rate—permits per 1,000 new residents over the past 5 years (is supply keeping up with demand). We then rescale these for easy comparison, show top and bottom performers for each metric, and create a composite score that highlights metros strong on both.\n\n\nShow code\n# Produces 5 tables total: 2 instantaneous, 2 rate-based, 1 composite.\n\nif (!requireNamespace(\"DT\", quietly = TRUE)) install.packages(\"DT\")\nif (!requireNamespace(\"htmltools\", quietly = TRUE)) install.packages(\"htmltools\")\nif (!requireNamespace(\"dplyr\", quietly = TRUE)) install.packages(\"dplyr\")\nif (!requireNamespace(\"scales\", quietly = TRUE)) install.packages(\"scales\")\n\nlibrary(DT); library(htmltools); library(dplyr); library(scales)\n\n# --- Build HG if it doesn't exist yet (uses POPULATION and PERMITS already in your doc) ---\nif (!exists(\"HG\")) {\n  # join POPULATION and PERMITS\n  pop_cbsa &lt;- POPULATION %&gt;%\n    select(GEOID, NAME, year, population) %&gt;%\n    mutate(CBSA = as.integer(GEOID))\n\n  permits_cbsa &lt;- PERMITS %&gt;%\n    select(CBSA, year, new_housing_units_permitted)\n\n  HG &lt;- permits_cbsa %&gt;%\n    inner_join(pop_cbsa, by = c(\"CBSA\",\"year\")) %&gt;%\n    arrange(CBSA, year) %&gt;%\n    group_by(CBSA) %&gt;%\n    mutate(\n      pop_5y_ago    = dplyr::lag(population, 5),\n      pop_growth_5y = population - pop_5y_ago\n    ) %&gt;%\n    ungroup()\n\n  # instantaneous metric (permits per 1,000 residents)\n  HG &lt;- HG %&gt;%\n    mutate(permits_per_1k = 1000 * new_housing_units_permitted / pmax(population, 1))\n\n  # baseline year for instantaneous index (first year available)\n  inst_base_year &lt;- min(HG$year, na.rm = TRUE)\n  inst_baseline  &lt;- HG %&gt;%\n    filter(year == inst_base_year) %&gt;%\n    summarise(base = 1000 * sum(new_housing_units_permitted, na.rm = TRUE) /\n                      pmax(sum(population, na.rm = TRUE), 1)) %&gt;%\n    pull(base)\n\n  HG &lt;- HG %&gt;%\n    mutate(inst_index_100_first = 100 * permits_per_1k / inst_baseline)\n\n  # rate-based metric (permits per 1,000 new residents over last 5y)\n  HG &lt;- HG %&gt;%\n    mutate(\n      pos_growth = is.finite(pop_growth_5y) & pop_growth_5y &gt; 0,\n      permits_per_1k_growth = dplyr::if_else(\n        pos_growth, 1000 * new_housing_units_permitted / pmax(pop_growth_5y, 1), NA_real_\n      )\n    )\n\n  # baseline year for rate-based index (first year with valid growth, ~2014)\n  rate_base_year &lt;- HG %&gt;%\n    filter(pos_growth, !is.na(permits_per_1k_growth)) %&gt;%\n    summarise(y = min(year, na.rm = TRUE)) %&gt;% pull(y)\n\n  rate_baseline &lt;- HG %&gt;%\n    filter(year == rate_base_year, pos_growth) %&gt;%\n    summarise(base = 1000 * sum(new_housing_units_permitted, na.rm = TRUE) /\n                      pmax(sum(pop_growth_5y, na.rm = TRUE), 1)) %&gt;%\n    pull(base)\n\n  HG &lt;- HG %&gt;%\n    mutate(rate_index_100_first = 100 * permits_per_1k_growth / rate_baseline)\n}\n\n# If the baseline-year variables don't exist (because HG existed already), derive them for captions:\nif (!exists(\"inst_base_year\")) {\n  inst_base_year &lt;- min(HG$year[is.finite(HG$inst_index_100_first)], na.rm = TRUE)\n}\nif (!exists(\"rate_base_year\")) {\n  rate_base_year &lt;- min(HG$year[is.finite(HG$rate_index_100_first)], na.rm = TRUE)\n}\n\nname_cols &lt;- c(\"NAME\",\"year\",\"new_housing_units_permitted\",\"population\")\n\n# Instantaneous (permits per 1,000 residents)\ninst_latest &lt;- max(HG$year[is.finite(HG$inst_index_100_first)], na.rm = TRUE)\ninst_tbl &lt;- HG %&gt;%\n  filter(year == inst_latest) %&gt;%\n  select(all_of(name_cols), permits_per_1k, inst_index_100_first) %&gt;%\n  arrange(desc(inst_index_100_first))\n\n# Table 1: Instantaneous TOP 15\n\nDT::datatable(\ninst_tbl %&gt;% slice_head(n = 15),\ncaption = tags$caption(style=\"caption-side: top; text-align: left;\",\npaste0(\"Instantaneous housing growth — TOP 15 (\", inst_latest,\n\"). Permits per 1,000 residents. Index 100 = national avg in \", inst_base_year)),\noptions = list(pageLength = 15)\n) %&gt;%\nDT::formatRound(c(\"permits_per_1k\",\"inst_index_100_first\"), 1) %&gt;%\nDT::formatCurrency(c(\"new_housing_units_permitted\",\"population\"), currency = \"\", digits = 0)\n\n\n\n\n\n\n\n\n\n\n\n\nAnalysis — Instantaneous (Top 15)\n\n\n\nThese metros are issuing the most permits per 1,000 residents in the latest year. High values signal strong near-term building relative to city size. Remember this is a one-year snapshot, so smaller CBSAs can rise to the top because each permit moves the rate more.\n\n\n\n\nShow code\n# Table 2: Instantaneous BOTTOM 15\n\nDT::datatable(\ninst_tbl %&gt;% slice_tail(n = 15) %&gt;% arrange(inst_index_100_first),\ncaption = tags$caption(style=\"caption-side: top; text-align: left;\",\npaste0(\"Instantaneous housing growth — BOTTOM 15 (\", inst_latest,\n\"). Permits per 1,000 residents. Index 100 = national avg in \", inst_base_year)),\noptions = list(pageLength = 15)\n) %&gt;%\nDT::formatRound(c(\"permits_per_1k\",\"inst_index_100_first\"), 1) %&gt;%\nDT::formatCurrency(c(\"new_housing_units_permitted\",\"population\"), currency = \"\", digits = 0)\n\n\n\n\n\n\nShow code\n# Rate-based (permits per 1,000 new residents over last 5y)\n\nrate_latest &lt;- max(HG$year[is.finite(HG$rate_index_100_first)], na.rm = TRUE)\nrate_tbl &lt;- HG %&gt;%\nfilter(year == rate_latest, is.finite(rate_index_100_first)) %&gt;%\nselect(all_of(name_cols), pop_growth_5y, permits_per_1k_growth, rate_index_100_first) %&gt;%\narrange(desc(rate_index_100_first))\n\n\n\n\n\n\n\n\nAnalysis — Instantaneous (Botton 15)\n\n\n\nThese metros permit comparatively little for their population right now. If population is growing, that can point to emerging supply pressure; if population is flat or falling, low permitting may simply match softer demand.\n\n\n\n\nShow code\n# Table 3: Rate-based TOP 15\n\nDT::datatable(\nrate_tbl %&gt;% slice_head(n = 15),\ncaption = tags$caption(style=\"caption-side: top; text-align: left;\",\npaste0(\"Growth-adjusted supply — TOP 15 (\", rate_latest,\n\"). Permits per 1,000 new residents (5y). Index 100 = national avg in \", rate_base_year)),\noptions = list(pageLength = 15)\n) %&gt;%\nDT::formatRound(c(\"permits_per_1k_growth\",\"rate_index_100_first\"), 1) %&gt;%\nDT::formatCurrency(c(\"new_housing_units_permitted\",\"population\",\"pop_growth_5y\"), currency = \"\", digits = 0)\n\n\n\n\n\n\n\n\n\n\n\n\nAnalysis — Rate-Based (Top 15)\n\n\n\nThese places permit a lot relative to their five-year population gains. Values above the baseline imply supply is keeping pace with recent inflows, which generally supports more stable prices over time.\n\n\n\n\nShow code\n# Table 4: Rate-based BOTTOM 15\n\nDT::datatable(\nrate_tbl %&gt;% slice_tail(n = 15) %&gt;% arrange(rate_index_100_first),\ncaption = tags$caption(style=\"caption-side: top; text-align: left;\",\npaste0(\"Growth-adjusted supply — BOTTOM 15 (\", rate_latest,\n\"). Permits per 1,000 new residents (5y). Index 100 = national avg in \", rate_base_year)),\noptions = list(pageLength = 15)\n) %&gt;%\nDT::formatRound(c(\"permits_per_1k_growth\",\"rate_index_100_first\"), 1) %&gt;%\nDT::formatCurrency(c(\"new_housing_units_permitted\",\"population\",\"pop_growth_5y\"), currency = \"\", digits = 0)\n\n\n\n\n\n\nShow code\n# -------------------- Composite (equal weights; each submetric rescaled 0–100) --------------------\n\nyears_inst_ok &lt;- HG %&gt;% filter(is.finite(inst_index_100_first)) %&gt;% pull(year) %&gt;% unique()\nyears_rate_ok &lt;- HG %&gt;% filter(is.finite(rate_index_100_first)) %&gt;% pull(year) %&gt;% unique()\ncomp_year &lt;- max(intersect(years_inst_ok, years_rate_ok))  # latest year with both submetrics\n\nHG_comp_year &lt;- HG %&gt;%\nfilter(year == comp_year, is.finite(inst_index_100_first), is.finite(rate_index_100_first))\n\nrng_inst &lt;- range(HG_comp_year$inst_index_100_first, na.rm = TRUE)\nrng_rate &lt;- range(HG_comp_year$rate_index_100_first, na.rm = TRUE)\n\nHG_comp_year &lt;- HG_comp_year %&gt;%\nmutate(\ninst_0_100 = scales::rescale(inst_index_100_first, to = c(0,100), from = rng_inst),\nrate_0_100 = scales::rescale(rate_index_100_first, to = c(0,100), from = rng_rate),\ncomposite  = 0.5 * inst_0_100 + 0.5 * rate_0_100\n)\n\ncomp_tbl &lt;- HG_comp_year %&gt;%\nselect(all_of(name_cols), permits_per_1k, inst_index_100_first,\npop_growth_5y, permits_per_1k_growth, rate_index_100_first,\ninst_0_100, rate_0_100, composite) %&gt;%\narrange(desc(composite))\n\n\n\n\n\n\n\n\nAnalysis — Rate-Based (Botton 15)\n\n\n\nPermits are low relative to five-year population growth, suggesting demand may be outrunning new supply. Interpret outliers carefully: very small recent growth can make this ratio volatile or missing when growth is non-positive.\n\n\n\n\nShow code\n# Table 5: Composite TOP 15\n\nDT::datatable(\ncomp_tbl %&gt;% slice_head(n = 15),\ncaption = tags$caption(style=\"caption-side: top; text-align: left;\",\npaste0(\"Composite YIMBY score — TOP 15 (\", comp_year,\n\"). Equal weights; instantaneous & growth-adjusted each rescaled 0–100\")),\noptions = list(pageLength = 15)\n) %&gt;%\nDT::formatRound(c(\"inst_index_100_first\",\"rate_index_100_first\",\"inst_0_100\",\"rate_0_100\",\"composite\"), 1) %&gt;%\nDT::formatRound(c(\"permits_per_1k\",\"permits_per_1k_growth\"), 1) %&gt;%\nDT::formatCurrency(c(\"new_housing_units_permitted\",\"population\",\"pop_growth_5y\"), currency = \"\", digits = 0)\n\n\n\n\n\n\n\n\n\n\n\n\nAnalysis — Composite (Top 15)\n\n\n\nThese metros perform well on both dimensions—high current permitting and good alignment with recent growth—after rescaling each to 0–100. Strong composite scores point to a more durable pro-building environment rather than a one-off spike."
  },
  {
    "objectID": "mp02.html#task-6-visualization",
    "href": "mp02.html#task-6-visualization",
    "title": "Mini Project 2: Making Backyards Affordable for All",
    "section": "Task 6: Visualization",
    "text": "Task 6: Visualization\n\n\nShow code\n# Visual 1:\n\nif (!exists(\"RB\") || !exists(\"HG\") || !exists(\"HOUSEHOLDS\")) {\n  stop(\"This chunk needs RB, HG, and HOUSEHOLDS created earlier.\")\n}\n\nif (!requireNamespace(\"tidyverse\", quietly = TRUE)) install.packages(\"tidyverse\")\nif (!requireNamespace(\"ggrepel\",  quietly = TRUE)) install.packages(\"ggrepel\")\nlibrary(dplyr); library(stringr); library(ggplot2); library(ggrepel); library(scales)\n\n# 1) Build CBSA-year frame with both indices\nif (!exists(\"yimby_data\")) {\n  HG_yearly &lt;- HG %&gt;%\n    mutate(composite_housing_index = rowMeans(\n      cbind(inst_index_100_first, rate_index_100_first), na.rm = TRUE\n    )) %&gt;%\n    select(CBSA, year, composite_housing_index)\n\n  yimby_data &lt;- RB %&gt;%\n    mutate(CBSA = as.integer(GEOID),\n           rent_burden_index = rb_index_100_first) %&gt;%\n    select(GEOID, NAME, CBSA, year, rent_burden_index) %&gt;%\n    left_join(HG_yearly, by = c(\"CBSA\",\"year\")) %&gt;%\n    left_join(HOUSEHOLDS %&gt;% select(GEOID, year, households),\n              by = c(\"GEOID\",\"year\"))\n}\n\n# 2) Aggregate 2019–2023 averages per CBSA\nviz &lt;- yimby_data %&gt;%\n  filter(year &gt;= 2019) %&gt;%\n  group_by(GEOID, NAME) %&gt;%\n  summarise(\n    avg_rb = mean(rent_burden_index, na.rm = TRUE),\n    avg_hg = mean(composite_housing_index, na.rm = TRUE),\n    hh_wt  = sum(households, na.rm = TRUE),\n    .groups = \"drop\"\n  ) %&gt;%\n  filter(is.finite(avg_rb), is.finite(avg_hg), hh_wt &gt; 0) %&gt;%\n  mutate(NAME_short = str_replace(NAME, \",.*\", \"\"))\n\n# 3) Household-weighted national means (dashed lines)\nrb_line &lt;- weighted.mean(viz$avg_rb, w = viz$hh_wt, na.rm = TRUE)\nhg_line &lt;- weighted.mean(viz$avg_hg, w = viz$hh_wt, na.rm = TRUE)\n\n# 4) Classify quadrants\nviz &lt;- viz %&gt;%\n  mutate(\n    quadrant = case_when(\n      avg_rb &gt;= rb_line & avg_hg &gt;= hg_line ~ \"High Rent, High Growth (YIMBY Success)\",\n      avg_rb &gt;= rb_line & avg_hg &lt;  hg_line ~ \"High Rent, Low Growth (NIMBY)\",\n      avg_rb &lt;  rb_line & avg_hg &gt;= hg_line ~ \"Low Rent, High Growth\",\n      TRUE                                  ~ \"Low Rent, Low Growth\"\n    )\n  )\n\n# 5) Cap extreme outliers so the cloud is readable\nx_lo &lt;- quantile(viz$avg_rb, 0.01, na.rm = TRUE)\nx_hi &lt;- quantile(viz$avg_rb, 0.99, na.rm = TRUE)\ny_lo &lt;- quantile(viz$avg_hg, 0.01, na.rm = TRUE)\ny_hi &lt;- quantile(viz$avg_hg, 0.99, na.rm = TRUE)\n\nviz_cap &lt;- viz %&gt;%\n  mutate(\n    x = pmin(pmax(avg_rb, x_lo), x_hi),\n    y = pmin(pmax(avg_hg, y_lo), y_hi),\n    dist2 = (avg_rb - rb_line)^2 + (avg_hg - hg_line)^2\n  )\n\n# 6) Pick a few labels per quadrant (furthest from center within caps)\nlabels_df &lt;- viz_cap %&gt;%\n  group_by(quadrant) %&gt;%\n  slice_max(dist2, n = 5, with_ties = FALSE) %&gt;%\n  ungroup()\n\n# 7) Background shading (intersect with axis limits)\nshade &lt;- tibble::tibble(\n  xmin = c(max(rb_line, x_lo), max(rb_line, x_lo), x_lo,          x_lo),\n  xmax = c(x_hi,               x_hi,               min(rb_line,x_hi), min(rb_line,x_hi)),\n  ymin = c(max(hg_line, y_lo), y_lo,               max(hg_line,y_lo), y_lo),\n  ymax = c(y_hi,               min(hg_line,y_hi),  y_hi,              min(hg_line,y_hi)),\n  fill = c(\"#1b9e7715\", \"#d95f0215\", \"#377eb815\", \"#80808015\")\n)\n\n# 8) Counts for each quadrant (printed on the chart)\ncounts &lt;- viz %&gt;% count(quadrant, name = \"n\")\npos_df &lt;- tibble::tibble(\n  quadrant = c(\"High Rent, High Growth (YIMBY Success)\",\n               \"High Rent, Low Growth (NIMBY)\",\n               \"Low Rent, High Growth\",\n               \"Low Rent, Low Growth\"),\n  x = c(x_hi - 0.5, x_hi - 0.5, x_lo + 0.5, x_lo + 0.5),\n  y = c(y_hi - 0.5, y_lo + 0.5, y_hi - 0.5, y_lo + 0.5),\n  hjust = c(1,1,0,0), vjust = c(1,0,1,0)\n) %&gt;% left_join(counts, by = \"quadrant\")\n\n# 9) Single, cleaner chart\nggplot(viz_cap, aes(x = x, y = y)) +\n  # quadrant shading & reference lines\n  geom_rect(data = shade,\n            aes(xmin = xmin, xmax = xmax, ymin = ymin, ymax = ymax),\n            inherit.aes = FALSE, fill = shade$fill, color = NA) +\n  geom_hline(yintercept = hg_line, linetype = \"dashed\", color = \"gray55\") +\n  geom_vline(xintercept = rb_line, linetype = \"dashed\", color = \"gray55\") +\n  # points (outlined for legibility)\n  geom_point(aes(color = quadrant), alpha = 0.85, size = 2.6, stroke = 0.25) +\n  # labels for a few exemplars\n  geom_text_repel(data = labels_df, aes(label = NAME_short),\n                  size = 3, max.overlaps = 40, min.segment.length = 0, seed = 42) +\n  # counts\n  geom_text(data = pos_df,\n            aes(x = x, y = y, label = paste0(n, \" CBSAs\"),\n                hjust = hjust, vjust = vjust),\n            inherit.aes = FALSE, fontface = \"bold\", size = 3.2) +\n  scale_x_continuous(limits = c(x_lo, x_hi), labels = label_number(accuracy = 1)) +\n  scale_y_continuous(limits = c(y_lo, y_hi), labels = label_comma(accuracy = 1)) +\n  scale_color_manual(\n    values = c(\"High Rent, High Growth (YIMBY Success)\" = \"#1b9e77\",\n               \"High Rent, Low Growth (NIMBY)\"         = \"#d95f02\",\n               \"Low Rent, High Growth\"                 = \"#377eb8\",\n               \"Low Rent, Low Growth\"                  = \"#7f7f7f\"),\n    name = \"Category\"\n  ) +\n  labs(\n    title = \"Rent Burden vs Housing Growth — recent average (2019–2023)\",\n    subtitle = paste0(\n      \"Dashed lines = household-weighted national means (RB ≈ \",\n      round(rb_line, 1), \", HG ≈ \", round(hg_line, 1),\n      \"). Axes capped at P1–P99 to reduce outlier distortion.\"\n    ),\n    x = \"Rent Burden Index\",\n    y = \"Housing Growth Index\",\n    caption = \"Sources: ACS (tidycensus) & BLS QCEW; indices from Tasks 4–5\"\n  ) +\n  theme_minimal(base_size = 12) +\n  theme(\n    legend.position = \"bottom\",\n    legend.title = element_blank(),\n    panel.grid.minor = element_blank()\n  ) +\n  guides(color = guide_legend(ncol = 2))\n\n\n\n\n\n\n\n\n\nYIMBY response (high rent, high growth): Salisbury; Myrtle Beach–Conway–North Myrtle Beach — strong permitting where rent burden is high.\nHealthy builders (low rent, high growth): Pittsburgh;Albany–Schenectady–Troy; Louisville–Jefferson County — building while keeping rents below average.\nNIMBY risk (high rent, low growth): Vineland–Bridgeton cluster — weak permitting with high rent burden.\n\n\nShow code\n# Visual 2\n\nif (!requireNamespace(\"tidyverse\", quietly = TRUE)) install.packages(\"tidyverse\")\nlibrary(dplyr); library(ggplot2); library(stringr); library(scales)\n\n# Pick a metro to highlight (uses yours if already set)\nif (!exists(\"target_cbsa_name\")) {\n  target_cbsa_name &lt;- \"New York-Newark-Jersey City, NY-NJ-PA Metro Area\"\n}\n\n# 1) Per-year distribution + national weighted average\nrb_stats &lt;- RB %&gt;%\n  group_by(year) %&gt;%\n  summarise(\n    us_weighted_avg = weighted.mean(rb_index_100_first, w = households, na.rm = TRUE),\n    p25 = quantile(rb_index_100_first, 0.25, na.rm = TRUE),\n    p75 = quantile(rb_index_100_first, 0.75, na.rm = TRUE),\n    .groups = \"drop\"\n  )\n\n# 2) Highlighted metro time series\nmetro_ts &lt;- RB %&gt;%\n  filter(NAME == target_cbsa_name) %&gt;%\n  arrange(year) %&gt;%\n  select(year, rb_index_100_first)\n\nlast_year &lt;- max(RB$year, na.rm = TRUE)\n\nggplot() +\n  # IQR ribbon across metros\n  geom_ribbon(data = rb_stats,\n              aes(x = year, ymin = p25, ymax = p75),\n              fill = \"#cbd5e1\", alpha = 0.6) +\n  # National weighted average\n  geom_line(data = rb_stats,\n            aes(year, us_weighted_avg),\n            linewidth = 1.1, color = \"#0f766e\") +\n  # Highlighted metro\n  geom_line(data = metro_ts,\n            aes(year, rb_index_100_first),\n            linewidth = 1.1, color = \"#1d4ed8\") +\n  # Baseline = 100 in first study year\n  geom_hline(yintercept = 100, linetype = \"dashed\", color = \"gray55\") +\n  labs(\n    title = \"Rent Burden Index Over Time\",\n    subtitle = paste0(\n      \"Shaded band = interquartile range across CBSAs. \",\n      \"Lines: US weighted average (green) vs. \",\n      str_replace(target_cbsa_name, \",.*\", \"\"), \" (blue).\"\n    ),\n    x = NULL,\n    y = \"Rent Burden Index (100 = national baseline in first year)\"\n  ) +\n  theme_minimal(base_size = 12) +\n  theme(\n    plot.title = element_text(face = \"bold\"),\n    panel.grid.minor = element_blank()\n  ) +\n  coord_cartesian(xlim = c(min(rb_stats$year, na.rm = TRUE), last_year))\n\n\n\n\n\n\n\n\n\nThe US household-weighted average rent burden stays above the 100 baseline by the most recent year, indicating rents have grown slightly faster than incomes nationwide.\nThe IQR ribbon shows meaningful cross-metro dispersion—affordability pressure is not uniform and varies widely by CBSA.\nThe highlighted metro tracks close to the national trend but remains on the higher side of the distribution in recent years, signaling persistent rent pressure despite some year-to-year easing.\nOverall, the pattern suggests moderate national strain with large local differences, consistent with supply and income dynamics varying across markets."
  },
  {
    "objectID": "mp02.html#task-7-policy-brief",
    "href": "mp02.html#task-7-policy-brief",
    "title": "Mini Project 2: Making Backyards Affordable for All",
    "section": "Task 7: Policy Brief",
    "text": "Task 7: Policy Brief"
  },
  {
    "objectID": "mp02.html#task-7-policy-brief-1",
    "href": "mp02.html#task-7-policy-brief-1",
    "title": "Mini Project 2: Making Backyards Affordable for All",
    "section": "Task 7: Policy Brief",
    "text": "Task 7: Policy Brief"
  },
  {
    "objectID": "mp02.html#policy-brief-federal-yimby-housing-program",
    "href": "mp02.html#policy-brief-federal-yimby-housing-program",
    "title": "Mini Project 2: Making Backyards Affordable for All",
    "section": "Policy Brief: Federal YIMBY Housing Program",
    "text": "Policy Brief: Federal YIMBY Housing Program\nMaking Rent Affordable for More Families\n\n1. Proposed Sponsors\n\nPrimary Sponsor (YIMBY Success Story)\nA representative from Myrtle Beach-Conway-North Myrtle Beach, SC.\nThis area has high rents but builds lots of new housing—keeping up with population growth. It shows YIMBY policies work.\n\n\nCo-Sponsor (Needs YIMBY Help)\nA representative from Vineland-Bridgeton, NJ.\nThis area has high rents but builds very little new housing. More housing here would lower costs for families.\n\n\n\n2. Local Groups to Rally Support\n\nRegistered Nurses\n\nBoth areas have big hospitals that need nurses.\n\nIn Myrtle Beach: More housing keeps rent low, so nurses spend less on housing.\n\nIn Vineland-Bridgeton: More housing would ease rent burdens, letting nurses save money.\n\n\n\nRetail Workers\n\nRetail jobs are common in both areas.\n\nIn Myrtle Beach: Affordable housing brings more workers, fixing store staffing shortages.\n\nIn Vineland-Bridgeton: Lower rent means people spend more at local shops—helping retail workers get more hours.\n\n\n\n\n3. Simple Metrics for Funding\n\nRent Burden Index\n\nShows how much of a household’s income goes to rent.\n\n100 = national average. Scores above 100 mean families spend more on rent than most.\n\n\n\nHousing Growth Index\n\nTracks how many new homes are built (for every 1,000 people) and if they keep up with population growth.\n\n100 = national average. Scores above 100 mean an area is building enough housing.\n\n\n\n\n4. Why This Bill Helps\n\nMyrtle Beach: Gets support to keep building affordable homes.\n\nVineland-Bridgeton: Gets help to build more, lowering rent for families.\n\nEveryone: Less money on rent means more for food, doctors, and local businesses.\n\nLET’S MAKE BACKYARDS AFFRORDABLE FOR ALL!"
  },
  {
    "objectID": "mp02.html#task-7-policy-brief---federal-yimby-housing-program",
    "href": "mp02.html#task-7-policy-brief---federal-yimby-housing-program",
    "title": "Mini Project 2: Making Backyards Affordable for All",
    "section": "Task 7: Policy Brief - Federal YIMBY Housing Program",
    "text": "Task 7: Policy Brief - Federal YIMBY Housing Program\nMaking Rent Affordable for More Families\n\n1. Proposed Sponsors\n\nPrimary Sponsor (YIMBY Success Story)\nA representative from Myrtle Beach-Conway-North Myrtle Beach, SC.\nThis area has high rents but builds lots of new housing—keeping up with population growth. It shows YIMBY policies work.\n\n\nCo-Sponsor (Needs YIMBY Help)\nA representative from Vineland-Bridgeton, NJ.\nThis area has high rents but builds very little new housing. More housing here would lower costs for families.\n\n\n\n2. Local Groups to Rally Support\n\nRegistered Nurses\n\nBoth areas have big hospitals that need nurses.\n\nIn Myrtle Beach: More housing keeps rent low, so nurses spend less on housing.\n\nIn Vineland-Bridgeton: More housing would ease rent burdens, letting nurses save money.\n\n\n\nRetail Workers\n\nRetail jobs are common in both areas.\n\nIn Myrtle Beach: Affordable housing brings more workers, fixing store staffing shortages.\n\nIn Vineland-Bridgeton: Lower rent means people spend more at local shops—helping retail workers get more hours.\n\n\n\n\n3. Simple Metrics for Funding\n\nRent Burden Index\n\nShows how much of a household’s income goes to rent.\n\n100 = national average. Scores above 100 mean families spend more on rent than most.\n\n\n\nHousing Growth Index\n\nTracks how many new homes are built (for every 1,000 people) and if they keep up with population growth.\n\n100 = national average. Scores above 100 mean an area is building enough housing.\n\n\n\n\n4. Why This Bill Helps\n\nMyrtle Beach: Gets support to keep building affordable homes.\n\nVineland-Bridgeton: Gets help to build more, lowering rent for families.\n\nEveryone: Less money on rent means more for food, doctors, and local businesses.\n\nLET’S MAKE BACKYARDS AFFRORDABLE FOR ALL!"
  },
  {
    "objectID": "mp02.html#extra-credit-opportunity-01-relationship-diagram",
    "href": "mp02.html#extra-credit-opportunity-01-relationship-diagram",
    "title": "Mini Project 2: Making Backyards Affordable for All",
    "section": "Extra Credit Opportunity #01: Relationship Diagram",
    "text": "Extra Credit Opportunity #01: Relationship Diagram\n\n\n\n\n\n\nEntities in the ERD and their roles\n\nPOPULATION(GEOID, NAME, population, year) → metro size and 5-year growth base.\nHOUSEHOLDS(GEOID, NAME, households, year) → weights for national averages and RB baseline.\nINCOME(GEOID, household_income, year) + RENT(GEOID, monthly_rent, year) → inputs to Rent Burden (RB).\nPERMITS(GEOID, year, building_permits) → supply flow; used in Housing Growth (HG).\nWAGES(FIPS, YEAR, EMPLOYMENT, INDUSTRY) + INDUSTRY_CODES(INDUSTRY, description) → occupations & allies for the policy brief.\n\n\nPrimary keys (composite): POPULATION/HOUSEHOLDS/INCOME/RENT: (GEOID, year) • PERMITS: (GEOID, year) • WAGES: (FIPS, YEAR, INDUSTRY) • INDUSTRY_CODES: (INDUSTRY)\n\n\n\nJoin pathways (how tables connect)\n\nACS core joins: INCOME, RENT, POPULATION, HOUSEHOLDS join on (GEOID, year).\nPermits to ACS:\n\nIf PERMITS already has GEOID (as in the ERD), join directly on (GEOID, year).\nIf source has CBSA codes, map CBSA→GEOID via a lookup; then join as above.\n\nWAGES to ACS: BLS uses FIPS like C3562. Create std_cbsa = FIPS || \"0\" so C3562 → C35620, which equals \"C\" + GEOID; link to ACS via a CBSA/GEOID lookup.\nYear coverage: ACS & QCEW omit 2020 → use intersecting years only in joins and summaries."
  }
]